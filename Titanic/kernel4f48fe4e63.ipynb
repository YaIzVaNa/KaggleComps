{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\npd.set_option('display.max_columns', None) # Setting pandas to display a N number of columns\npd.set_option('display.max_rows', None) # Setting pandas to display a N number rows\npd.set_option('display.width', 1000) # Setting pandas dataframe display width to N\n\nimport pandas_profiling \n\ntrain = pd.read_csv('../input/titanic/train.csv')\ntest = pd.read_csv('../input/titanic/test.csv')\ndataset = [train, test]\n\n# Let's get a summary of our datasets\n\nprint('Entries in training set: ', len(train), '\\nEntries in testing set: ',len(test))\n\nfor df in dataset:\n    print(df.isna().sum())\n\n# A combination of training and test dataset would be helpful in data analysis\n\ntrain_test_comb = pd.concat([train, test], axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering Section","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Sex to number","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in dataset:\n    df['Age'].fillna(df['Age'].mean(), inplace=True)\n    df['Fare'].fillna(df['Fare'].mean(), inplace=True)\n    df.Sex.replace({'female':0, 'male': 1}, inplace=True)\n    df['FamSize']=df['SibSp']+df['Parch']\n    df.drop(['Cabin','Ticket','SibSp','Parch'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We believe cabin, passengerid and ticket number have no effect on the causation of survival rate","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Identify titles of each person","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in dataset:\n    df['Title'] = df['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n    print(list(df['Title'].unique()))\n    # Replace the titles that has less than 20 ocurrences with 'Misc'\n    title_names = (df['Title'].value_counts()> 5) #this will create a true false series with title name as index\n    df['Title'] = df['Title'].apply(lambda x: x if title_names.loc[x] == True else 'Misc')\n    df.drop(['Name'],axis=1,inplace=True)\nprint(train['Title'].value_counts())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in dataset:\n    df['Fare_cat'] = pd.qcut(df['Fare'], q=4, labels=(1,2,3,4))\n    df['Age_cat'] = pd.qcut(df['Age'], q=4, labels=(1,2,3,4))\n    df.drop(['Fare','Age'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counts = train[\"Age_cat\"].value_counts()\npercent100 = train[\"Age_cat\"].value_counts(normalize=True).mul(100).round(1).astype(str) + '%'\nacc_day=pd.DataFrame({'counts': counts, 'Percent': percent100})\nprint(acc_day)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A hypothesis is that port of embarkment is not relevant to survival","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['Embarked'],axis=1,inplace=True)\ntest.drop(['Embarked'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in dataset:\n    # Convert category dtypes to integers\n    df['Age_cat'] = df['Age_cat'].astype(np.int32)\n    df['Fare_cat'] = df['Fare_cat'].astype(np.int32)\n    # lambda function to change the values of 'Familysize'\n    df['FamSize'] = df['FamSize'].apply(lambda x: 'Alone' if x==0 else('Small' if x>0 and x<5 else('Medium' if x>=5 and x<7 else 'Large')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-hot encoding\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n\nfeatures = ['Age_cat', 'Fare_cat', 'Pclass', 'Sex', 'Title', 'FamSize']\nencoded_features = []\n\nfor df in dataset:\n  for feature in features:\n    encoded = OneHotEncoder().fit_transform(df[feature].values.reshape(-1, 1)).toarray()\n    cols = [f'{feature}_{n}' for idx, n in enumerate(df[feature].unique())]\n    encoded_df = pd.DataFrame(encoded, columns=cols)\n    encoded_df.index = df.index\n    encoded_features.append(encoded_df)\n\ntrain_one = pd.concat([train, *encoded_features[:6]], axis=1)\ntest_one = pd.concat([test, *encoded_features[6:]], axis=1)\n\ndataset = [train_one, test_one]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in dataset:\n    df.drop(['Pclass','Sex','FamSize','Title'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nfeatures = [x for x in train_one.columns if x!='Survived']\n\nx = train_one[features].to_numpy()\ny = train_one['Survived'].to_numpy()\n\nx_train, x_val, y_train, y_val = train_test_split(x, y, train_size = int(0.85*len(train_one)), shuffle=False ,random_state=1912)\n\nprint(x_train.shape, y_train.shape, x_val.shape, y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nclf = RandomForestClassifier(criterion='gini', \n                        n_estimators=300,\n                        max_depth=4,\n                        min_samples_split=4,\n                        min_samples_leaf=7,\n                        max_features='auto',\n                        oob_score=True,\n                        random_state=1400,\n                        n_jobs=-1)\n\nclf.fit(x_train, y_train)\n\ny_pred = clf.predict(x_val)\n\ncm = confusion_matrix(y_val, y_pred)\nprint(cm)\nprint(classification_report(y_val, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newcols=np.zeros(len(test_one))\ntest_one['Title_Dr']=newcols\ntest_one['Title_Rev']=newcols\nindexes=pd.DataFrame(test_one.index.values)\nindexes.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = test_one[features].to_numpy()\n\nprediction_clf = clf.predict(test_data)\nprint(len(prediction_clf))\n\noutput = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': prediction_clf})\noutput.to_csv('/kaggle/working/my_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}